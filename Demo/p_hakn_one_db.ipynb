{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "> **Essential ML process for Intrusion Detection**\n",
    "<br>` python  3.7.13    scikit-learn  1.0.2 `\n",
    "<br>`numpy   1.19.5          pandas  1.3.5`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_S34U5S-i69d"
   },
   "source": [
    "**Import the main libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "\n",
    "from time import time\n",
    "\n",
    "import os\n",
    "data_path = '../datasets/NSL_KDD'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "_import the local library_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add parent folder path where lib folder is\n",
    "import sys\n",
    "if \"..\" not in sys.path:import sys; sys.path.insert(0, '..') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mylib import show_labels_dist, show_metrics, bias_var_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9IZetEZ8jQJm"
   },
   "source": [
    "**Import the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset: 63280 rows, 43 columns\n",
      "Test Dataset: 22544 rows, 43 columns\n"
     ]
    }
   ],
   "source": [
    "# Using boosted Train and preprocessed Test\n",
    "\n",
    "data_file = os.path.join(data_path, 'NSL_boosted-2.csv') \n",
    "train_df = pandas.read_csv(data_file)\n",
    "print('Train Dataset: {} rows, {} columns'.format(train_df.shape[0], train_df.shape[1]))\n",
    "\n",
    "data_file = os.path.join(data_path, 'NSL_ppTest.csv') \n",
    "test_df = pandas.read_csv(data_file)\n",
    "print('Test Dataset: {} rows, {} columns'.format(test_df.shape[0], test_df.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg"
   },
   "source": [
    "***\n",
    "**Data Preparation and EDA** (unique to this dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "* _Check column names of numeric attributes_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "trnn = train_df.select_dtypes(include=['float64','int64']).columns\n",
    "tstn = test_df.select_dtypes(include=['float64','int64']).columns\n",
    "trndif = numpy.setdiff1d(trnn, tstn)\n",
    "tstdif = numpy.setdiff1d(tstn, trnn)\n",
    "\n",
    "print(\"Numeric features in the train_set that are not in the test_set: \",end='')\n",
    "if len(trndif) > 0:\n",
    "    print('\\n',trndif)\n",
    "else:\n",
    "    print('None')\n",
    "\n",
    "print(\"Numeric features in the test_set that are not in the train_set: \",end='')\n",
    "if len(tstdif) > 0:\n",
    "    print('\\n',tstdif)\n",
    "else:\n",
    "    print('None')\n",
    "\n",
    "print()\n",
    "# correct any differences here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _Check column names of categorical attributes_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "trnn = train_df.select_dtypes(include=['object']).columns\n",
    "tstn = test_df.select_dtypes(include=['object']).columns\n",
    "trndif = numpy.setdiff1d(trnn, tstn)\n",
    "tstdif = numpy.setdiff1d(tstn, trnn)\n",
    "\n",
    "print(\"Categorical features in the train_set that are not in the test_set: \",end='')\n",
    "if len(trndif) > 0:\n",
    "    print('\\n',trndif)\n",
    "else:\n",
    "    print('None')\n",
    "\n",
    "print(\"Categorical features in the test_set that are not in the train_set: \",end='')\n",
    "if len(tstdif) > 0:\n",
    "    print('\\n\\t',tstdif)\n",
    "else:\n",
    "    print('None')\n",
    "\n",
    "print()\n",
    "# correct any differences here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _Check for missing values_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "cnt=0\n",
    "print('Missing Values - Train Set')\n",
    "for col in train_df.columns:\n",
    "#    print(col, ' ::> ', len(combined_df[col].unique()))\n",
    "    nnul = pandas.notnull(train_df[col]) \n",
    "    if (len(nnul)!=len(train_df)):\n",
    "        cnt=cnt+1\n",
    "        print('\\t',col,':',(len(test_df)-len(nnul)),'null values')\n",
    "print('Total',cnt,'features with null values')\n",
    "\n",
    "cnt=0\n",
    "print('Missing Values - Test Set')\n",
    "for col in test_df.columns:\n",
    "#    print(col, ' ::> ', len(combined_df[col].unique()))\n",
    "    nnul = pandas.notnull(test_df[col]) \n",
    "    if (len(nnul)!=len(test_df)):\n",
    "        cnt=cnt+1\n",
    "        print('\\t',col,':',(len(test_df)-len(nnul)),'null values')\n",
    "print('Total',cnt,'features with null values')\n",
    "\n",
    "# address missing values here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _Quick visual check of unique values, deal with unique identifiers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique value count: Train ( 63280 rows ) ~ Test( 22544 rows )\n"
     ]
    }
   ],
   "source": [
    "# Identify columns with only one value \n",
    "# or with number of unique values == number of rows\n",
    "n_eq_one = []\n",
    "n_eq_all = []\n",
    "\n",
    "print('Unique value count: Train (',train_df.shape[0],'rows ) ~ Test(',test_df.shape[0],'rows )')\n",
    "for col in train_df.columns:\n",
    "    lctrn = len(train_df[col].unique())\n",
    "    lctst = len(test_df[col].unique())\n",
    "\n",
    "#    print(col, ' ::> ', lctrn, ' ~ ', lctst)\n",
    "    \n",
    "    if (lctrn == 1) and (lctrn == lctst): \n",
    "        n_eq_one.append(train_df[col].name)\n",
    "    if lctrn == train_df.shape[0]:\n",
    "        n_eq_all.append(train_df[col].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping single-valued features\n",
      "['num_outbound_cmds']\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with only one value\n",
    "if len(n_eq_one) > 0:\n",
    "    print('Dropping single-valued features')\n",
    "    print(n_eq_one)\n",
    "    train_df.drop(n_eq_one, axis=1, inplace=True)\n",
    "    test_df.drop(n_eq_one, axis=1, inplace=True)\n",
    "\n",
    "# Drop or bin columns with number of unique values == number of rows\n",
    "if len(n_eq_all) > 0:\n",
    "    print('Dropping unique identifiers')\n",
    "    print(n_eq_all)\n",
    "    train_df.drop(n_eq_all, axis=1, inplace=True)\n",
    "    test_df.drop(n_eq_all, axis=1, inplace=True)\n",
    "\n",
    "# continue with featue selection / feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _Check categorical feature values:<br>\n",
    "differences will be resolved by one-hot encoding the combined test and train sets_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "trnn = train_df.select_dtypes(include=['object']).columns\n",
    "for col in trnn:\n",
    "    tr = train_df[col].unique()\n",
    "    ts = test_df[col].unique()\n",
    "    trd = numpy.setdiff1d(tr, ts)\n",
    "    tsd = numpy.setdiff1d(ts, tr)\n",
    "    \n",
    "    print(col,'::> ')\n",
    "    print(\"\\tUnique text values in the train_set that are not in the test_set: \",end='')\n",
    "    if len(trd) > 0:\n",
    "        print('\\n\\t',trd)\n",
    "    else:\n",
    "        print('None')\n",
    "    \n",
    "    print(\"\\tUnique text values in the test_set that are not in the train_set: \",end='')\n",
    "    if len(tsd) > 0:\n",
    "        print('\\n\\t',tsd)\n",
    "    else:\n",
    "        print('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _Combine for processing classification target and text features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Dataset: 85824 rows, 42 columns\n"
     ]
    }
   ],
   "source": [
    "combined_df = pandas.concat([train_df, test_df])\n",
    "print('Combined Dataset: {} rows, {} columns'.format(\n",
    "    combined_df.shape[0], combined_df.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _Classification Target feature:_\n",
    "two columns of labels are available \n",
    "    * Two-class: Reduce the detailed attack labels to 'normal' or 'attack'\n",
    "    * Multiclass: Use the category labels (atakcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#combined_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#combined_df['atakcat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the classification target\n",
    "twoclass = True     # True or False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if twoclass:\n",
    "# Two-class: Reduce the detailed attack labels to 'normal' or 'attack'\n",
    "# new single column data structure is a [series]\n",
    "    labels_df = combined_df['label'].copy()\n",
    "    labels_df[labels_df != 'normal'] = 'attack'\n",
    "else:\n",
    "# Multiclass: Use the category labels (atakcat)\n",
    "# new single column data structure is a [[dataframe]]\n",
    "# rename the column and convert to a series for later\n",
    "    labels_df = combined_df[['atakcat']].copy()\n",
    "    labels_df.rename(columns={'atakcat':'label'}, inplace=True)\n",
    "    labels_df = labels_df.squeeze('columns')\n",
    "\n",
    "# drop target features \n",
    "combined_df.drop(['label'], axis=1, inplace=True)\n",
    "combined_df.drop(['atakcat'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "* _One-Hot Encoding the categorical (text) features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['protocol_type', 'service', 'flag']\n"
     ]
    }
   ],
   "source": [
    "# put the names into a python list - for pandas.get_dummies()\n",
    "categori = combined_df.select_dtypes(include=['object']).columns\n",
    "category_cols = categori.tolist()\n",
    "print(category_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "protocol_type  ::>  ['icmp' 'tcp' 'udp']\n",
      "\n",
      "service  ::>  ['IRC' 'X11' 'Z39_50' 'aol' 'auth' 'bgp' 'courier' 'csnet_ns' 'ctf'\n",
      " 'daytime' 'discard' 'domain' 'domain_u' 'echo' 'eco_i' 'ecr_i' 'efs'\n",
      " 'exec' 'finger' 'ftp' 'ftp_data' 'gopher' 'harvest' 'hostnames' 'http'\n",
      " 'http_2784' 'http_443' 'http_8001' 'imap4' 'iso_tsap' 'klogin' 'kshell'\n",
      " 'ldap' 'link' 'login' 'mtp' 'name' 'netbios_dgm' 'netbios_ns'\n",
      " 'netbios_ssn' 'netstat' 'nnsp' 'nntp' 'ntp_u' 'other' 'pm_dump' 'pop_2'\n",
      " 'pop_3' 'printer' 'private' 'red_i' 'remote_job' 'rje' 'shell' 'smtp'\n",
      " 'sql_net' 'ssh' 'sunrpc' 'supdup' 'systat' 'telnet' 'tftp_u' 'tim_i'\n",
      " 'time' 'urh_i' 'urp_i' 'uucp' 'uucp_path' 'vmnet' 'whois']\n",
      "\n",
      "flag  ::>  ['OTH' 'REJ' 'RSTO' 'RSTOS0' 'RSTR' 'S0' 'S1' 'S2' 'S3' 'SF' 'SH']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate a sorted list of unique values of categorical features\n",
    "# we will get a new column for each one with get_dummies()\n",
    "\n",
    "for col in categori:\n",
    "    ul = numpy.sort(list(combined_df[col].unique()))\n",
    "    print(col, ' ::> ', ul)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 85824 entries, 0 to 22543\n",
      "Columns: 121 entries, duration to flag_SH\n",
      "dtypes: float64(15), int64(22), uint8(84)\n",
      "memory usage: 31.8 MB\n"
     ]
    }
   ],
   "source": [
    "# Apply to the list of Categorical columns (text fields)\n",
    "features_df = pandas.get_dummies(combined_df, columns=category_cols)\n",
    "features_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate']\n"
     ]
    }
   ],
   "source": [
    "# generate a list of numeric columns for scaling - After test // train split\n",
    "numeri = combined_df.select_dtypes(include=['float64','int64']).columns\n",
    "print(numeri.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg",
    "tags": []
   },
   "source": [
    "***\n",
    "**<br>Create Test // Train Datasets**\n",
    "> Normally we split the dataset into train 70 % // test 30 % like this\n",
    "<br>`from sklearn.model_selection import train_test_split`\n",
    "<br>`X_train, X_test, y_train, y_test = `\n",
    "<br>`    train_test_split(features_df, labels_df, `\n",
    "<br>`        test_size=0.3, stratify=labels_df, random_state=42)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Restore the train // test split: slice 1 Dataframe into 2 \n",
    "features_train = features_df.iloc[:len(train_df),:].copy()    # X_train\n",
    "features_train.reset_index(inplace=True, drop=True)\n",
    "# pandas has a lot of rules about returning a 'view' vs. a copy from slice\n",
    "# so we force it to create a new dataframe [avoiding SettingWithCopy Warning]\n",
    "features_test = features_df.iloc[len(train_df):,:].copy()     # X_test\n",
    "features_test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Restore the train // test split: slice 1 Series into 2 \n",
    "labels_train = labels_df[:len(train_df)]               # y_train\n",
    "labels_train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "labels_test = labels_df[len(train_df):]                # y_test\n",
    "labels_test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "Next are standard steps for all datasets: _scaling, classifiers, results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg",
    "tags": []
   },
   "source": [
    "**Scaling** comes _after_ test // train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scaling the Numeric columns \n",
    "# StandardScaler range: -1 to 1, MinMaxScaler range: zero to 1\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# sklearn docs say \n",
    "#   \"Don't cheat - fit only on training data, then transform both\"\n",
    "#   fit() expects 2D array: reshape(-1, 1) for single col or (1, -1) single row\n",
    "\n",
    "for i in numeri:\n",
    "    arr = numpy.array(features_train[i])\n",
    "    scale = MinMaxScaler().fit(arr.reshape(-1, 1))\n",
    "    features_train[i] = scale.transform(arr.reshape(len(arr),1))\n",
    "\n",
    "    arr = numpy.array(features_test[i])\n",
    "    features_test[i] = scale.transform(arr.reshape(len(arr),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg",
    "tags": []
   },
   "source": [
    "**<br>Classifier Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('StocGradDes', SGDClassifier()), ('LinearDA', LinearDiscriminantAnalysis()), ('LinearSVC', LinearSVC()), ('RidgeClf', RidgeClassifier()), ('DecisionTree', DecisionTreeClassifier()), ('RandomForest', RandomForestClassifier())]\n"
     ]
    }
   ],
   "source": [
    "# prepare list\n",
    "models = []\n",
    "\n",
    "##  --  Linear  --  ## \n",
    "#from sklearn.linear_model import LogisticRegression \n",
    "#models.append ((\"LogReg\",LogisticRegression())) \n",
    "from sklearn.linear_model import SGDClassifier \n",
    "models.append ((\"StocGradDes\",SGDClassifier())) \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "models.append((\"LinearDA\", LinearDiscriminantAnalysis())) \n",
    "#from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis \n",
    "#models.append((\"QuadraticDA\", QuadraticDiscriminantAnalysis())) \n",
    "\n",
    "##  --  Support Vector  --  ## \n",
    "#from sklearn.svm import SVC \n",
    "#models.append((\"SupportVectorClf\", SVC())) \n",
    "from sklearn.svm import LinearSVC \n",
    "models.append((\"LinearSVC\", LinearSVC())) \n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "models.append ((\"RidgeClf\",RidgeClassifier())) \n",
    "\n",
    "##  --  Non-linear  --  ## \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "models.append ((\"DecisionTree\",DecisionTreeClassifier())) \n",
    "#from sklearn.naive_bayes import GaussianNB \n",
    "#models.append ((\"GaussianNB\",GaussianNB())) \n",
    "#from sklearn.neighbors import KNeighborsClassifier \n",
    "#models.append((\"K-NNeighbors\", KNeighborsClassifier())) \n",
    "\n",
    "##  --  Ensemble: bagging  --  ## \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "models.append((\"RandomForest\", RandomForestClassifier())) \n",
    "##  --  Ensemble: boosting  --  ## \n",
    "#from sklearn.ensemble import AdaBoostClassifier \n",
    "#models.append((\"AdaBoost\", AdaBoostClassifier())) \n",
    "#from sklearn.ensemble import GradientBoostingClassifier \n",
    "#models.append((\"GradientBoost\", GradientBoostingClassifier())) \n",
    "\n",
    "##  --  NeuralNet (simplest)  --  ## \n",
    "#from sklearn.linear_model import Perceptron \n",
    "#models.append ((\"SingleLayerPtron\",Perceptron())) \n",
    "#from sklearn.neural_network import MLPClassifier \n",
    "#models.append((\"MultiLayerPtron\", MLPClassifier())) \n",
    "\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>_compatibility block for pasting in from sample code_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset names\n",
    "X_train = features_train\n",
    "y_train = labels_train\n",
    "X_test = features_test\n",
    "y_test = labels_test\n",
    "labels_col = 'label'\n",
    "# library names\n",
    "pd = pandas\n",
    "np = numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**<br>Target Label Distributions** (standard block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_train: 63280 rows, 121 columns\n",
      "features_test:  22544 rows, 121 columns\n",
      "\n",
      "labels_train: 63280 rows, 1 column\n",
      "labels_test:  22544 rows, 1 column\n",
      "\n",
      "Frequency and Distribution of labels\n",
      "        label  %_train  label  %_test\n",
      "normal  33672    53.21   9711   43.08\n",
      "attack  29608    46.79  12833   56.92\n"
     ]
    }
   ],
   "source": [
    "# from our local library\n",
    "show_labels_dist(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg",
    "tags": []
   },
   "source": [
    "_... this is a good place for the ClassBalance visualizer ..._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg"
   },
   "source": [
    "**<br>Fit and Predict** (standard block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix: StocGradDes\n",
      "Run Time 0.69 seconds\n",
      "              pred:attack  pred:normal\n",
      "train:attack         8153         4680\n",
      "train:normal          712         8999\n",
      "\n",
      "Confusion Matrix: LinearDA\n",
      "Run Time 3.02 seconds\n",
      "              pred:attack  pred:normal\n",
      "train:attack         8346         4487\n",
      "train:normal          663         9048\n",
      "\n",
      "Confusion Matrix: LinearSVC\n",
      "Run Time 4.32 seconds\n",
      "              pred:attack  pred:normal\n",
      "train:attack         8317         4516\n",
      "train:normal          735         8976\n",
      "\n",
      "Confusion Matrix: RidgeClf\n",
      "Run Time 0.88 seconds\n",
      "              pred:attack  pred:normal\n",
      "train:attack         8345         4488\n",
      "train:normal          664         9047\n",
      "\n",
      "Confusion Matrix: DecisionTree\n",
      "Run Time 2.58 seconds\n",
      "              pred:attack  pred:normal\n",
      "train:attack        11089         1744\n",
      "train:normal          917         8794\n",
      "\n",
      "Confusion Matrix: RandomForest\n",
      "Run Time 21.31 seconds\n",
      "              pred:attack  pred:normal\n",
      "train:attack        10616         2217\n",
      "train:normal          869         8842\n"
     ]
    }
   ],
   "source": [
    "# evaluate each model in turn\n",
    "results = []\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#print('macro average: unweighted mean per label')\n",
    "#print('weighted average: support-weighted mean per label')\n",
    "#print('MCC: correlation between prediction and ground truth')\n",
    "#print('     (+1 perfect, 0 random prediction, -1 inverse)\\n')\n",
    "\n",
    "for name, clf in models:\n",
    "    trs = time()\n",
    "    print('\\nConfusion Matrix:', name)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    ygx = clf.predict(X_test)\n",
    "    results.append((name, ygx))\n",
    "    \n",
    "    tre = time() - trs\n",
    "    print (\"Run Time {} seconds\".format(round(tre,2)))\n",
    "    \n",
    "# Easy way to ensure that the confusion matrix rows and columns\n",
    "#   are labeled exactly as the classifier has coded the classes\n",
    "#   [[note the _ at the end of clf.classes_ ]]\n",
    "\n",
    "    tptn_df = pd.DataFrame(confusion_matrix(y_test, ygx, labels=clf.classes_), \n",
    "                           index=['train:{:}'.format(x) for x in clf.classes_], \n",
    "                           columns=['pred:{:}'.format(x) for x in clf.classes_])\n",
    "    print(tptn_df)  \n",
    "\n",
    "#    show_metrics(y_test, ygx, clf.classes_)   # from our local library\n",
    "#    print('\\nParameters: ', clf.get_params(), '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg",
    "tags": []
   },
   "source": [
    "**Bias - Variance Decomposition** (standard block)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "# from our local library\n",
    "# reduce (cross-validation) folds for faster results\n",
    "folds = 20\n",
    "for name, clf in models:\n",
    "    print('Bias // Variance Decomposition:', name)\n",
    "    bias_var_metrics(X_train,X_test,y_train,y_test,clf,folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg"
   },
   "source": [
    "**<br>Baseline Model**\n",
    ">Select this block - Go to the Run menu - Run all Above\n",
    "<br> Then paste in blocks below from the other examples  \n",
    "and run them one at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg"
   },
   "source": [
    "***\n",
    "**Statistical Comparison of Models**\n",
    "<br>The the null hypothesis statement:\n",
    ">H0: Both models perform equally well on the dataset.\n",
    "<br>H1: Both models do not have the same performance on the dataset.\n",
    "\n",
    "Chosen significance threshold is `alpha = 0.05` for rejecting the null hypothesis.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cochran's Q omnibus test<br>\n",
    "* McNemar post-hoc with multiple adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nonparametric tests for one performance measure (e.g., AUC)\n",
    "from P_HAK import cq_mph, ap2h0   # ,run_friedman, stac_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_pvals_df = cq_mph(y_test,results)\n",
    "ph_pvals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_pvals_df = cq_mph(y_test,results,cq=False,control='RidgeClf')\n",
    "ph_pvals_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg",
    "tags": []
   },
   "source": [
    " ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz=ap2h0(ph_pvals_df)\n",
    "zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = ph_pvals_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.columns = tt.columns.str.replace('ap_', 'H0: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.drop(['H0:no_a'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = (tt>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
